{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YnFdyWyqB42"
   },
   "source": [
    "<h1><strong>GridSearch para Redes Neurais Recorrentes (RNN) na Predição do Mercado Financeiro</strong></h1>\n",
    "<h4><strong>SOBRE O ARQUIVO</strong></h4>\n",
    "<p align=\"justify\">&emsp;Este arquivo complementa o projeto \"Modelos de Machine Learning Aplicados ao Mercado Financeiro\", mais especificamente, ele foi utilizado antes do Arquivo Principal \"PredicaoMercadoFinanceiro.ipynb\". Neste arquivo, abordamos os possíveis parâmetros e a melhor escolha desses parâmetros para serem utilizadas nos modelos do Arquivo Principal.</p>\n",
    "<br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OvlEw5i0HIxl"
   },
   "source": [
    "<h4><strong>ÍNDICE</strong></h4>\n",
    "<a href = \"#1\">1. Tratamento da Base de Dados</a>\n",
    "<br>\n",
    "<a href = \"#2\">2. GridSearch SimpleRNN</a>\n",
    "<br>\n",
    "&emsp;<a href = \"#2.1\">2.1 SimpleRNN - Dataset Cru</a>\n",
    "<br>\n",
    "&emsp;<a href = \"#2.2\">2.2 SimpleRNN - Dataset com Ruído</a>\n",
    "<br>\n",
    "<a href = \"#3\">3. GridSearch LSTM</a>\n",
    "<br>\n",
    "&emsp;<a href = \"#3.1\">3.1 LSTM - Dataset Cru</a>\n",
    "<br>\n",
    "&emsp;<a href = \"#3.2\">3.2 LSTM - Dataset com Ruído</a>\n",
    "<br><br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2l2TLMZ-G8AQ"
   },
   "source": [
    "<h4><strong>1. TRATAMENTO DA BASE DE DADOS</strong></h4>\n",
    "<a id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tc0haO_drC2d"
   },
   "outputs": [],
   "source": [
    "# -- INTALAÇÃO DE BIBLIOTÉCAS NECESSÁRIAS --\n",
    "# !pip install yfinance\n",
    "# !pip install tensorflow\n",
    "# !pip install pandas\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hs_Yfn9gqSXf"
   },
   "outputs": [],
   "source": [
    "# -- ADIQUIRINDO ACESSO AS INFORMAÇÕES DA AÇÃO --\n",
    "# Lista de tickets de ações a serem utilizadas\n",
    "acao = \"VALE3.SA\"\n",
    "\n",
    "# Adquirindo e tratando os valores das ações\n",
    "import yfinance as yf\n",
    "data = yf.download( tickers = acao, period = \"8d\", interval = \"1m\", auto_adjust = True, ignore_tz = True )\n",
    "data.dropna( inplace = True ) # removendo valores nulos\n",
    "display( data[ \"Close\" ] )\n",
    "dt = data.index # salvando as datas e o tempo para visualização\n",
    "data = data[ \"Close\" ].values # mantendo apenas os valores dos dados de fechamento (o valor no momento em que o registro foi feito)\n",
    "\n",
    "# Criando as variáções do dataset\n",
    "import random as rnd\n",
    "import numpy as np\n",
    "import copy\n",
    "data_raw = data[:]\n",
    "data_noise = list()\n",
    "for i in data_raw:\n",
    "  data_noise.append(i + rnd.gauss(0, 0.1))\n",
    "data_noise = np.array( data_noise )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lPJQb2CDGBZy"
   },
   "outputs": [],
   "source": [
    "# Exibição dos Diferentes Dataset's\n",
    "janela_visualizacao = len(data_raw)\n",
    "tick_indices = range( 0, len( dt[ -janela_visualizacao - 1 : ] ), 200)\n",
    "tick_labels = list( dt[ -janela_visualizacao - 1 : : 200] )\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[ \"figure.figsize\" ] = ( 12, 4 )\n",
    "plt.plot( data_noise, label = 'Dataset com Ruído', alpha = 0.8, color = 'yellowgreen' )\n",
    "plt.plot( data_raw, label = 'Dataset Cru', alpha = 0.8, color = 'firebrick' )\n",
    "plt.title( f\"DATASET's\", fontsize = 14 )\n",
    "plt.xlabel( \"Tempo\" )\n",
    "plt.xticks( tick_indices, tick_labels, rotation = 45 )\n",
    "plt.ylabel( \"Preço (R$)\" )\n",
    "plt.legend()\n",
    "plt.grid( True )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yaQ5HM4kqkvX"
   },
   "outputs": [],
   "source": [
    "# -- TRATANDO E DIVIDINDO OS DADOS DA AÇÃO --\n",
    "# Função para a criação de janelas deslizantes\n",
    "def create_dataset( series, janela = 10 ):\n",
    "  X, y = [], []\n",
    "  for i in range( 0, len( series ) - janela ):\n",
    "    X.append( series[ i : i + janela ] )\n",
    "    y.append( series[ i + janela ] )\n",
    "  return np.array( X ), np.array( y )\n",
    "\n",
    "# Inicialização do scaler para a normalização\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler( feature_range = ( 0, 1 ) )\n",
    "\n",
    "train_size = int( 0.8 * len( data_raw ) )\n",
    "# DATASET CRU\n",
    "# Divisão treino/teste\n",
    "train_data_raw, test_data_raw = data_raw[ : train_size ], data_raw[ train_size : ]\n",
    "# Normalização dos dados\n",
    "train_data_raw = scaler.fit_transform( train_data_raw.reshape( -1, 1 ) )\n",
    "test_data_raw = scaler.transform( test_data_raw.reshape( -1, 1 ) )\n",
    "\n",
    "# DATASET COM RUÍDO\n",
    "# Divisão treino/teste\n",
    "train_data_noise, test_data_noise = data_noise[ : train_size ], data_noise[ train_size : ]\n",
    "# Normalização dos dados\n",
    "train_data_noise = scaler.fit_transform( train_data_noise.reshape( -1, 1 ) )\n",
    "test_data_noise = scaler.transform( test_data_noise.reshape( -1, 1 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ZPN811lGz1k"
   },
   "source": [
    "<br><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4iYNGyoGlzM"
   },
   "source": [
    "<h4><strong>2. GRIDSEARCH SIMPLE_RNN</strong></h4>\n",
    "<a id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q91btGALHzVJ"
   },
   "outputs": [],
   "source": [
    "# -- OPÇÕES GLOBAIS --\n",
    "num_layers_options = [1, 2]\n",
    "window_size_options = [10, 20, 30, 40, 50]\n",
    "neurons_options = [32, 64, 128, 256]\n",
    "activation_options = ['relu', 'tanh', 'sigmoid']\n",
    "batch_size_options = [16, 32, 64]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4b81hk7lPbOC"
   },
   "source": [
    "<h5><strong>2.1 Dataset Cru</strong></h5>\n",
    "<a id = \"2.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-TjUsXfGlIA"
   },
   "outputs": [],
   "source": [
    "# -- GRIDSEARCH PARA O DATASET CRU --\n",
    "# Lista para armazenar os resultados\n",
    "results_raw_SimpleRNN = list()\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import product\n",
    "\n",
    "for num_layers in num_layers_options:\n",
    "  if num_layers == 1:\n",
    "    for ws, h, act, bs in product( window_size_options, neurons_options, activation_options, batch_size_options ):\n",
    "      print( f\"Testando: num_layers = {num_layers}, janela = {ws}, hidden = {h}, activation = {act}, batch_size = {bs}\" )\n",
    "      # Criação das janelas\n",
    "      X_test, y_test = create_dataset( test_data_raw, ws )\n",
    "      X_train_raw, y_train_raw = create_dataset( train_data_raw, ws )\n",
    "\n",
    "      # Crição do modelo\n",
    "      model_raw_SimpleRNN = Sequential()\n",
    "      model_raw_SimpleRNN.add( SimpleRNN( units = h, activation = act, input_shape = ( ws, 1 ) ) )\n",
    "      model_raw_SimpleRNN.add( Dense( units = 1 ) )\n",
    "      model_raw_SimpleRNN.compile( optimizer = \"adam\", loss = \"mean_squared_error\" )\n",
    "\n",
    "      # Treinamento do modelo\n",
    "      model_raw_SimpleRNN.fit( X_train_raw, y_train_raw, epochs = 100, batch_size = bs, verbose = 0 )\n",
    "\n",
    "      # Salvando o resultado\n",
    "      y_real = scaler.inverse_transform( y_test )\n",
    "      y_pred_raw = scaler.inverse_transform( model_raw_SimpleRNN.predict( X_test ) )\n",
    "      mse = mean_squared_error( y_real, y_pred_raw )\n",
    "      results_raw_SimpleRNN.append( ( ( num_layers, ws, h, act, bs ), mse ) )\n",
    "  else:\n",
    "    for ws, h1, h2, act, bs in product( window_size_options, neurons_options, neurons_options, activation_options, batch_size_options ):\n",
    "      print( f\"Testando: num_layers = {num_layers}, janela = {ws}, hidden1 = {h1}, hidden2 = {h2}, activation = {act}, batch_size = {bs}\" )\n",
    "      # Criação das janelas\n",
    "      X_test, y_test = create_dataset( test_data_raw, ws )\n",
    "      X_train_raw, y_train_raw = create_dataset( train_data_raw, ws )\n",
    "\n",
    "      # Crição do modelo\n",
    "      model_raw_SimpleRNN = Sequential()\n",
    "      model_raw_SimpleRNN.add( SimpleRNN( units = h1, activation = act, return_sequences = True, input_shape = ( ws, 1 ) ) )\n",
    "      model_raw_SimpleRNN.add( SimpleRNN( units = h2, activation = act ) )\n",
    "      model_raw_SimpleRNN.add( Dense( units = 1 ) )\n",
    "      model_raw_SimpleRNN.compile( optimizer = \"adam\", loss = \"mean_squared_error\" )\n",
    "\n",
    "      # Treinamento do modelo\n",
    "      model_raw_SimpleRNN.fit( X_train_raw, y_train_raw, epochs = 100, batch_size = bs, verbose = 0 )\n",
    "\n",
    "      # Salvando o resultado\n",
    "      y_real = scaler.inverse_transform( y_test )\n",
    "      y_pred_raw = scaler.inverse_transform( model_raw_SimpleRNN.predict( X_test ) )\n",
    "      mse = mean_squared_error( y_real, y_pred_raw )\n",
    "      results_raw_SimpleRNN.append( ( ( num_layers, ws, h1, h2, act, bs ), mse ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0gYJ97z5c6mn"
   },
   "outputs": [],
   "source": [
    "# -- OBTER O MELHOR MODELO DO DATASET CRU --\n",
    "best_model_raw_SimpleRNN = min( results_raw_SimpleRNN, key=lambda x: x[ 1 ] )\n",
    "if best_model_raw_SimpleRNN[ 0 ][ 0 ] == 1:\n",
    "  num_layers, ws, h, act, bs = best_model_raw_SimpleRNN[ 0 ]\n",
    "  print( f\"Melhor modelo: num_layers = {num_layers}, janela = {ws}, hidden = {h}, activation = {act}, batch_size = {bs}\" )\n",
    "else:\n",
    "  num_layers, ws, h1, h2, act, bs = best_model_raw_SimpleRNN[ 0 ]\n",
    "  print( f\"Melhor modelo: num_layers = {num_layers}, janela = {ws}, hidden1 = {h1}, hidden2 = {h2}, activation = {act}, batch_size = {bs}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "669-vpJZPrZW"
   },
   "source": [
    "<h5><strong>2.2 Dataset com Ruído</strong></h5>\n",
    "<a id = \"2.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0KdqOgXKxf_C"
   },
   "outputs": [],
   "source": [
    "# -- GRIDSEARCH PARA O DATASET COM RUÍDO --\n",
    "# Lista para armazenar os resultados\n",
    "results_noise_SimpleRNN = list()\n",
    "for num_layers in num_layers_options:\n",
    "  if num_layers == 1:\n",
    "    for ws, h, act, bs in product( window_size_options, neurons_options, activation_options, batch_size_options ):\n",
    "      print( f\"Testando: num_layers = {num_layers}, janela = {ws}, hidden = {h}, activation = {act}, batch_size = {bs}\" )\n",
    "      # Criação das janelas\n",
    "      X_test, y_test = create_dataset( test_data_raw, ws )\n",
    "      X_train_noise, y_train_noise = create_dataset( train_data_noise, ws )\n",
    "\n",
    "      # Crição do modelo\n",
    "      model_noise_SimpleRNN = Sequential()\n",
    "      model_noise_SimpleRNN.add( SimpleRNN( units = h, activation = act, input_shape = ( ws, 1 ) ) )\n",
    "      model_noise_SimpleRNN.add( Dense( units = 1 ) )\n",
    "      model_noise_SimpleRNN.compile( optimizer = \"adam\", loss = \"mean_squared_error\" )\n",
    "\n",
    "      # Treinamento do modelo\n",
    "      model_noise_SimpleRNN.fit( X_train_noise, y_train_noise, epochs = 100, batch_size = bs, verbose = 0 )\n",
    "\n",
    "      # Salvando o resultado\n",
    "      y_real = scaler.inverse_transform( y_test )\n",
    "      y_pred_noise = scaler.inverse_transform( model_noise_SimpleRNN.predict( X_test ) )\n",
    "      mse = mean_squared_error( y_real, y_pred_noise )\n",
    "      results_noise_SimpleRNN.append( ( ( num_layers, ws, h, act, bs ), mse ) )\n",
    "  else:\n",
    "    for ws, h1, h2, act, bs in product( window_size_options, neurons_options, neurons_options, activation_options, batch_size_options ):\n",
    "      print( f\"Testando: num_layers = {num_layers}, janela = {ws}, hidden1 = {h1}, hidden2 = {h2}, activation = {act}, batch_size = {bs}\" )\n",
    "      # Criação das janelas\n",
    "      X_test, y_test = create_dataset( test_data_raw, ws )\n",
    "      X_train_noise, y_train_noise = create_dataset( train_data_noise, ws )\n",
    "\n",
    "      # Crição do modelo\n",
    "      model_noise_SimpleRNN = Sequential()\n",
    "      model_noise_SimpleRNN.add( SimpleRNN( units = h1, activation = act, return_sequences = True, input_shape = ( ws, 1 ) ) )\n",
    "      model_noise_SimpleRNN.add( SimpleRNN( units = h2, activation = act ) )\n",
    "      model_noise_SimpleRNN.add( Dense( units = 1 ) )\n",
    "      model_noise_SimpleRNN.compile( optimizer = \"adam\", loss = \"mean_squared_error\" )\n",
    "\n",
    "      # Treinamento do modelo\n",
    "      model_noise_SimpleRNN.fit( X_train_noise, y_train_noise, epochs = 100, batch_size = bs, verbose = 0 )\n",
    "\n",
    "      # Salvando o resultado\n",
    "      y_real = scaler.inverse_transform( y_test )\n",
    "      y_pred_noise = scaler.inverse_transform( model_noise_SimpleRNN.predict( X_test ) )\n",
    "      mse = mean_squared_error( y_real, y_pred_noise )\n",
    "      results_noise_SimpleRNN.append( ( ( num_layers, ws, h1, h2, act, bs ), mse ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNoL0yeVDVkQ"
   },
   "outputs": [],
   "source": [
    "# -- OBTER O MELHOR MODELO DO DATASET COM RUÍDO --\n",
    "best_model_noise_SimpleRNN = min( results_noise_SimpleRNN, key=lambda x: x[ 1 ] )\n",
    "if best_model_noise_SimpleRNN[ 0 ][ 0 ] == 1:\n",
    "  num_layers, ws, h, act, bs = best_model_noise_SimpleRNN[ 0 ]\n",
    "  print( f\"Melhor modelo: num_layers = {num_layers}, janela = {ws}, hidden = {h}, activation = {act}, batch_size = {bs}\" )\n",
    "else:\n",
    "  num_layers, ws, h1, h2, act, bs = best_model_noise_SimpleRNN[ 0 ]\n",
    "  print( f\"Melhor modelo: num_layers = {num_layers}, janela = {ws}, hidden1 = {h1}, hidden2 = {h2}, activation = {act}, batch_size = {bs}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3J1qwzqowkj"
   },
   "source": [
    "<br><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8-auxY3P56Q"
   },
   "source": [
    "<h4><strong>3. GRIDSEARCH LSTM</strong></h4>\n",
    "<a id = \"3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IluxmZjQpXeb"
   },
   "outputs": [],
   "source": [
    "# -- OPÇÕES GLOBAIS -- (As mesmas opções que a do SimpleRNN )\n",
    "# num_layers_options = [1, 2]\n",
    "# window_size_options = [10, 20, 30, 40, 50]\n",
    "# neurons_options = [32, 64, 128, 256]\n",
    "# activation_options = ['relu', 'tanh', 'sigmoid']\n",
    "# batch_size_options = [16, 32, 64]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ez7OvJhFpXeb"
   },
   "source": [
    "<h5><strong>3.1 Dataset Cru</strong></h5>\n",
    "<a id = \"3.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JvJi_l9IpXec"
   },
   "outputs": [],
   "source": [
    "# -- GRIDSEARCH PARA O DATASET CRU --\n",
    "# Lista para armazenar os resultados\n",
    "results_raw_LSTM = list()\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import product\n",
    "for num_layers in num_layers_options:\n",
    "  if num_layers == 1:\n",
    "    for ws, h, act, bs in product( window_size_options, neurons_options, activation_options, batch_size_options ):\n",
    "      print( f\"Testando: num_layers = {num_layers}, janela = {ws}, hidden = {h}, activation = {act}, batch_size = {bs}\" )\n",
    "      # Criação das janelas\n",
    "      X_test, y_test = create_dataset( test_data_raw, ws )\n",
    "      X_train_raw, y_train_raw = create_dataset( train_data_raw, ws )\n",
    "\n",
    "      # Crição do modelo\n",
    "      model_raw_LSTM = Sequential()\n",
    "      model_raw_LSTM.add( LSTM( units = h, activation = act, input_shape = ( ws, 1 ) ) )\n",
    "      model_raw_LSTM.add( Dense( units = 1 ) )\n",
    "      model_raw_LSTM.compile( optimizer = \"adam\", loss = \"mean_squared_error\" )\n",
    "\n",
    "      # Treinamento do modelo\n",
    "      model_raw_LSTM.fit( X_train_raw, y_train_raw, epochs = 100, batch_size = bs, verbose = 0 )\n",
    "\n",
    "      # Salvando o resultado\n",
    "      y_real = scaler.inverse_transform( y_test )\n",
    "      y_pred_raw = scaler.inverse_transform( model_raw_LSTM.predict( X_test ) )\n",
    "      mse = mean_squared_error( y_real, y_pred_raw )\n",
    "      results_raw_LSTM.append( ( ( num_layers, ws, h, act, bs ), mse ) )\n",
    "  else:\n",
    "    for ws, h1, h2, act, bs in product( window_size_options, neurons_options, neurons_options, activation_options, batch_size_options ):\n",
    "      print( f\"Testando: num_layers = {num_layers}, janela = {ws}, hidden1 = {h1}, hidden2 = {h2}, activation = {act}, batch_size = {bs}\" )\n",
    "      # Criação das janelas\n",
    "      X_test, y_test = create_dataset( test_data_raw, ws )\n",
    "      X_train_raw, y_train_raw = create_dataset( train_data_raw, ws )\n",
    "\n",
    "      # Crição do modelo\n",
    "      model_raw_LSTM = Sequential()\n",
    "      model_raw_LSTM.add( LSTM( units = h1, activation = act, return_sequences = True, input_shape = ( ws, 1 ) ) )\n",
    "      model_raw_LSTM.add( LSTM( units = h2, activation = act ) )\n",
    "      model_raw_LSTM.add( Dense( units = 1 ) )\n",
    "      model_raw_LSTM.compile( optimizer = \"adam\", loss = \"mean_squared_error\" )\n",
    "\n",
    "      # Treinamento do modelo\n",
    "      model_raw_LSTM.fit( X_train_raw, y_train_raw, epochs = 100, batch_size = bs, verbose = 0 )\n",
    "\n",
    "      # Salvando o resultado\n",
    "      y_real = scaler.inverse_transform( y_test )\n",
    "      y_pred_raw = scaler.inverse_transform( model_raw_LSTM.predict( X_test ) )\n",
    "      mse = mean_squared_error( y_real, y_pred_raw )\n",
    "      results_raw_LSTM.append( ( ( num_layers, ws, h1, h2, act, bs ), mse ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vrF3TS25pXec"
   },
   "outputs": [],
   "source": [
    "# -- OBTER O MELHOR MODELO DO DATASET CRU --\n",
    "best_model_raw_LSTM = min( results_raw_LSTM, key=lambda x: x[ 1 ] )\n",
    "if best_model_raw_LSTM[ 0 ][ 0 ] == 1:\n",
    "  num_layers, ws, h, act, bs = best_model_raw_LSTM[ 0 ]\n",
    "  print( f\"Melhor modelo: num_layers = {num_layers}, janela = {ws}, hidden = {h}, activation = {act}, batch_size = {bs}\" )\n",
    "else:\n",
    "  num_layers, ws, h1, h2, act, bs = best_model_raw_LSTM[ 0 ]\n",
    "  print( f\"Melhor modelo: num_layers = {num_layers}, janela = {ws}, hidden1 = {h1}, hidden2 = {h2}, activation = {act}, batch_size = {bs}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJww8xYhpXec"
   },
   "source": [
    "<h5><strong>3.2 Dataset com Ruído</strong></h5>\n",
    "<a id = \"3.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N3PYHBN9pXec"
   },
   "outputs": [],
   "source": [
    "# -- GRIDSEARCH PARA O DATASET COM RUÍDO --\n",
    "# Lista para armazenar os resultados\n",
    "results_noise_LSTM = list()\n",
    "for num_layers in num_layers_options:\n",
    "  if num_layers == 1:\n",
    "    for ws, h, act, bs in product( window_size_options, neurons_options, activation_options, batch_size_options ):\n",
    "      print( f\"Testando: num_layers = {num_layers}, janela = {ws}, hidden = {h}, activation = {act}, batch_size = {bs}\" )\n",
    "      # Criação das janelas\n",
    "      X_test, y_test = create_dataset( test_data_raw, ws )\n",
    "      X_train_noise, y_train_noise = create_dataset( train_data_noise, ws )\n",
    "\n",
    "      # Crição do modelo\n",
    "      model_noise_LSTM = Sequential()\n",
    "      model_noise_LSTM.add( LSTM( units = h, activation = act, input_shape = ( ws, 1 ) ) )\n",
    "      model_noise_LSTM.add( Dense( units = 1 ) )\n",
    "      model_noise_LSTM.compile( optimizer = \"adam\", loss = \"mean_squared_error\" )\n",
    "\n",
    "      # Treinamento do modelo\n",
    "      model_noise_LSTM.fit( X_train_noise, y_train_noise, epochs = 100, batch_size = bs, verbose = 0 )\n",
    "\n",
    "      # Salvando o resultado\n",
    "      y_real = scaler.inverse_transform( y_test )\n",
    "      y_pred_noise = scaler.inverse_transform( model_noise_LSTM.predict( X_test ) )\n",
    "      mse = mean_squared_error( y_real, y_pred_noise )\n",
    "      results_noise_LSTM.append( ( ( num_layers, ws, h, act, bs ), mse ) )\n",
    "  else:\n",
    "    for ws, h1, h2, act, bs in product( window_size_options, neurons_options, neurons_options, activation_options, batch_size_options ):\n",
    "      print( f\"Testando: num_layers = {num_layers}, janela = {ws}, hidden1 = {h1}, hidden2 = {h2}, activation = {act}, batch_size = {bs}\" )\n",
    "      # Criação das janelas\n",
    "      X_test, y_test = create_dataset( test_data_raw, ws )\n",
    "      X_train_noise, y_train_noise = create_dataset( train_data_noise, ws )\n",
    "\n",
    "      # Crição do modelo\n",
    "      model_noise_LSTM = Sequential()\n",
    "      model_noise_LSTM.add( LSTM( units = h1, activation = act, return_sequences = True, input_shape = ( ws, 1 ) ) )\n",
    "      model_noise_LSTM.add( LSTM( units = h2, activation = act ) )\n",
    "      model_noise_LSTM.add( Dense( units = 1 ) )\n",
    "      model_noise_LSTM.compile( optimizer = \"adam\", loss = \"mean_squared_error\" )\n",
    "\n",
    "      # Treinamento do modelo\n",
    "      model_noise_LSTM.fit( X_train_noise, y_train_noise, epochs = 100, batch_size = bs, verbose = 0 )\n",
    "\n",
    "      # Salvando o resultado\n",
    "      y_real = scaler.inverse_transform( y_test )\n",
    "      y_pred_noise = scaler.inverse_transform( model_noise_LSTM.predict( X_test ) )\n",
    "      mse = mean_squared_error( y_real, y_pred_noise )\n",
    "      results_noise_LSTM.append( ( ( num_layers, ws, h1, h2, act, bs ), mse ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VChK8mhwpXed"
   },
   "outputs": [],
   "source": [
    "# -- OBTER O MELHOR MODELO DO DATASET CRU --\n",
    "best_model_noise_LSTM = min( results_noise_LSTM, key=lambda x: x[ 1 ] )\n",
    "if best_model_noise_LSTM[ 0 ][ 0 ] == 1:\n",
    "  num_layers, ws, h, act, bs = best_model_noise_LSTM[ 0 ]\n",
    "  print( f\"Melhor modelo: num_layers = {num_layers}, janela = {ws}, hidden = {h}, activation = {act}, batch_size = {bs}\" )\n",
    "else:\n",
    "  num_layers, ws, h1, h2, act, bs = best_model_noise_LSTM[ 0 ]\n",
    "  print( f\"Melhor modelo: num_layers = {num_layers}, janela = {ws}, hidden1 = {h1}, hidden2 = {h2}, activation = {act}, batch_size = {bs}\" )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
